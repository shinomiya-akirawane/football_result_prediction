{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"Data_Files 2023/final_train_data.csv\")\n",
    "test_dataset = pd.read_csv(\"Data_Files 2023/final_test_data.csv\")\n",
    "\n",
    "\n",
    "X_train = train_dataset.drop('FTR', axis=1)\n",
    "y_train = train_dataset['FTR']\n",
    "X_test = test_dataset.drop('FTR', axis=1)\n",
    "y_test = test_dataset['FTR']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85       516\n",
      "           1       0.59      0.71      0.64       421\n",
      "           2       0.91      0.82      0.86       831\n",
      "\n",
      "    accuracy                           0.80      1768\n",
      "   macro avg       0.78      0.79      0.78      1768\n",
      "weighted avg       0.82      0.80      0.81      1768\n",
      "\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       516\n",
      "           1       0.57      0.58      0.57       421\n",
      "           2       0.88      0.82      0.85       831\n",
      "\n",
      "    accuracy                           0.77      1768\n",
      "   macro avg       0.74      0.74      0.74      1768\n",
      "weighted avg       0.77      0.77      0.77      1768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # Hyper tuning for logistic regression\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'max_iter': [100, 500, 1000, 1500, 2000, 2500]\n",
    "}\n",
    "\n",
    "additional_combinations = [\n",
    "    {'solver': 'newton-cg', 'penalty': 'l2'},\n",
    "    {'solver': 'sag', 'penalty': 'l2'},\n",
    "    {'solver': 'saga', 'penalty': 'l1'},\n",
    "]\n",
    "\n",
    "param_distributions['solver'].extend([comb['solver'] for comb in additional_combinations])\n",
    "param_distributions['penalty'].extend([comb['penalty'] for comb in additional_combinations])\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(LogisticRegression(), param_distributions, \n",
    "                            n_iter=10, scoring='accuracy', cv=5, random_state=42)\n",
    " \n",
    "search.fit(X_train, y_train)\n",
    "best_params = search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "best_model_lr = search.best_estimator_\n",
    "print(search.best_estimator_)\n",
    "best_model_lr.set_params(max_iter=2000)\n",
    "best_model_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model_lr.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Logistic Regression: \",report)\n",
    " \"\"\"\n",
    "\n",
    "# Best logistic regression model after hyper tuning\n",
    "best_lr_para_model = LogisticRegression(C=1, max_iter=2500, solver='sag')\n",
    "best_lr_para_model.fit(X_train, y_train)\n",
    "y_pred = best_lr_para_model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Logistic Regression\")\n",
    "print(report)\n",
    "\"\"\" \n",
    "# Hyper tuning for svm\n",
    "param_distributions = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "    'degree': [2, 3, 4, 5], \n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1, 10], \n",
    "    'shrinking': [True, False], \n",
    "    'probability': [True, False],  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(SVC(), param_distributions, \n",
    "                            n_iter=10, scoring='accuracy', cv=5, random_state=42)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "best_params = search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "best_model_lr = search.best_estimator_\n",
    "\n",
    "best_model_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model_lr.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"SVC: \",report)\n",
    " \"\"\"\n",
    "# Best svm model after hyper tuning\n",
    "# best_svc_para_model = SVC(C=0.1, gamma=1, kernel='poly', shrinking=False)\n",
    "best_svc_para_model = SVC(shrinking=False, probability=False, kernel='poly', gamma=1, degree=3, C=0.1)\n",
    "best_svc_para_model.fit(X_train, y_train)\n",
    "y_pred = best_svc_para_model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"SVM\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
