{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('E:/学习/UCL/year-3/comp0036/final_train_data.csv')\n",
    "test_dataset = pd.read_csv('E:/学习/UCL/year-3/comp0036/final_test_data.csv')\n",
    "\n",
    "X_train = train_dataset.drop('FTR', axis=1)\n",
    "y_train = train_dataset['FTR']\n",
    "X_test = test_dataset.drop('FTR', axis=1)\n",
    "y_test = test_dataset['FTR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for measuring training time\n",
    "from time import time \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    \n",
    "    return f1_score(target, y_pred, average='micro'), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(f1, acc)\n",
    "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Scores: [0.51649485 0.50128932 0.54357916 0.51933987 0.54151625]\n",
      "Mean Accuracy: 0.5244438891340526\n",
      "Training a GaussianNB using a training set size of 9696. . .\n",
      "Trained model in 0.0355 seconds\n",
      "Made predictions in 0.0406 seconds.\n",
      "0.5410478547854786 0.5410478547854786\n",
      "F1 score and accuracy score for training set: 0.5410 , 0.5410.\n",
      "Made predictions in 0.0112 seconds.\n",
      "F1 score and accuracy score for test set: 0.5492 , 0.5492.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the NB model\n",
    "clf_nb = GaussianNB()\n",
    "clf_nb.fit(X_train, y_train)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(clf_nb, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy scores for each fold\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "train_predict(clf_nb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'colsample_bytree': 0.45212112147976885, 'learning_rate': 0.062475643163223786, 'max_depth': 4, 'n_estimators': 188, 'subsample': 0.8582458280396085}\n",
      "Best Score: 0.8970\n",
      "[0]\tvalidation_0-mlogloss:1.06792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\86182\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalidation_0-mlogloss:1.03200\n",
      "[2]\tvalidation_0-mlogloss:0.99914\n",
      "[3]\tvalidation_0-mlogloss:0.97144\n",
      "[4]\tvalidation_0-mlogloss:0.94531\n",
      "[5]\tvalidation_0-mlogloss:0.91833\n",
      "[6]\tvalidation_0-mlogloss:0.88988\n",
      "[7]\tvalidation_0-mlogloss:0.86595\n",
      "[8]\tvalidation_0-mlogloss:0.84080\n",
      "[9]\tvalidation_0-mlogloss:0.81825\n",
      "[10]\tvalidation_0-mlogloss:0.79966\n",
      "[11]\tvalidation_0-mlogloss:0.78110\n",
      "[12]\tvalidation_0-mlogloss:0.75932\n",
      "[13]\tvalidation_0-mlogloss:0.74518\n",
      "[14]\tvalidation_0-mlogloss:0.72816\n",
      "[15]\tvalidation_0-mlogloss:0.71157\n",
      "[16]\tvalidation_0-mlogloss:0.69383\n",
      "[17]\tvalidation_0-mlogloss:0.68000\n",
      "[18]\tvalidation_0-mlogloss:0.66811\n",
      "[19]\tvalidation_0-mlogloss:0.65383\n",
      "[20]\tvalidation_0-mlogloss:0.64255\n",
      "[21]\tvalidation_0-mlogloss:0.62675\n",
      "[22]\tvalidation_0-mlogloss:0.61653\n",
      "[23]\tvalidation_0-mlogloss:0.61105\n",
      "[24]\tvalidation_0-mlogloss:0.60239\n",
      "[25]\tvalidation_0-mlogloss:0.59222\n",
      "[26]\tvalidation_0-mlogloss:0.58275\n",
      "[27]\tvalidation_0-mlogloss:0.56972\n",
      "[28]\tvalidation_0-mlogloss:0.56127\n",
      "[29]\tvalidation_0-mlogloss:0.54869\n",
      "[30]\tvalidation_0-mlogloss:0.54019\n",
      "[31]\tvalidation_0-mlogloss:0.52930\n",
      "[32]\tvalidation_0-mlogloss:0.52192\n",
      "[33]\tvalidation_0-mlogloss:0.51544\n",
      "[34]\tvalidation_0-mlogloss:0.51133\n",
      "[35]\tvalidation_0-mlogloss:0.50721\n",
      "[36]\tvalidation_0-mlogloss:0.50104\n",
      "[37]\tvalidation_0-mlogloss:0.49344\n",
      "[38]\tvalidation_0-mlogloss:0.48448\n",
      "[39]\tvalidation_0-mlogloss:0.48018\n",
      "[40]\tvalidation_0-mlogloss:0.47459\n",
      "[41]\tvalidation_0-mlogloss:0.46834\n",
      "[42]\tvalidation_0-mlogloss:0.46440\n",
      "[43]\tvalidation_0-mlogloss:0.45832\n",
      "[44]\tvalidation_0-mlogloss:0.45534\n",
      "[45]\tvalidation_0-mlogloss:0.45055\n",
      "[46]\tvalidation_0-mlogloss:0.44527\n",
      "[47]\tvalidation_0-mlogloss:0.44090\n",
      "[48]\tvalidation_0-mlogloss:0.43504\n",
      "[49]\tvalidation_0-mlogloss:0.42829\n",
      "[50]\tvalidation_0-mlogloss:0.42284\n",
      "[51]\tvalidation_0-mlogloss:0.41866\n",
      "[52]\tvalidation_0-mlogloss:0.41353\n",
      "[53]\tvalidation_0-mlogloss:0.40887\n",
      "[54]\tvalidation_0-mlogloss:0.40301\n",
      "[55]\tvalidation_0-mlogloss:0.39760\n",
      "[56]\tvalidation_0-mlogloss:0.39454\n",
      "[57]\tvalidation_0-mlogloss:0.39004\n",
      "[58]\tvalidation_0-mlogloss:0.38669\n",
      "[59]\tvalidation_0-mlogloss:0.38267\n",
      "[60]\tvalidation_0-mlogloss:0.37878\n",
      "[61]\tvalidation_0-mlogloss:0.37657\n",
      "[62]\tvalidation_0-mlogloss:0.37305\n",
      "[63]\tvalidation_0-mlogloss:0.36932\n",
      "[64]\tvalidation_0-mlogloss:0.36575\n",
      "[65]\tvalidation_0-mlogloss:0.36235\n",
      "[66]\tvalidation_0-mlogloss:0.35890\n",
      "[67]\tvalidation_0-mlogloss:0.35673\n",
      "[68]\tvalidation_0-mlogloss:0.35374\n",
      "[69]\tvalidation_0-mlogloss:0.35197\n",
      "[70]\tvalidation_0-mlogloss:0.34979\n",
      "[71]\tvalidation_0-mlogloss:0.34671\n",
      "[72]\tvalidation_0-mlogloss:0.34401\n",
      "[73]\tvalidation_0-mlogloss:0.34049\n",
      "[74]\tvalidation_0-mlogloss:0.33864\n",
      "[75]\tvalidation_0-mlogloss:0.33646\n",
      "[76]\tvalidation_0-mlogloss:0.33464\n",
      "[77]\tvalidation_0-mlogloss:0.33090\n",
      "[78]\tvalidation_0-mlogloss:0.32843\n",
      "[79]\tvalidation_0-mlogloss:0.32547\n",
      "[80]\tvalidation_0-mlogloss:0.32367\n",
      "[81]\tvalidation_0-mlogloss:0.32215\n",
      "[82]\tvalidation_0-mlogloss:0.31942\n",
      "[83]\tvalidation_0-mlogloss:0.31763\n",
      "[84]\tvalidation_0-mlogloss:0.31636\n",
      "[85]\tvalidation_0-mlogloss:0.31319\n",
      "[86]\tvalidation_0-mlogloss:0.31070\n",
      "[87]\tvalidation_0-mlogloss:0.30883\n",
      "[88]\tvalidation_0-mlogloss:0.30739\n",
      "[89]\tvalidation_0-mlogloss:0.30499\n",
      "[90]\tvalidation_0-mlogloss:0.30369\n",
      "[91]\tvalidation_0-mlogloss:0.30229\n",
      "[92]\tvalidation_0-mlogloss:0.30069\n",
      "[93]\tvalidation_0-mlogloss:0.29905\n",
      "[94]\tvalidation_0-mlogloss:0.29677\n",
      "[95]\tvalidation_0-mlogloss:0.29427\n",
      "[96]\tvalidation_0-mlogloss:0.29288\n",
      "[97]\tvalidation_0-mlogloss:0.29161\n",
      "[98]\tvalidation_0-mlogloss:0.29017\n",
      "[99]\tvalidation_0-mlogloss:0.28818\n",
      "[100]\tvalidation_0-mlogloss:0.28639\n",
      "[101]\tvalidation_0-mlogloss:0.28476\n",
      "[102]\tvalidation_0-mlogloss:0.28273\n",
      "[103]\tvalidation_0-mlogloss:0.28106\n",
      "[104]\tvalidation_0-mlogloss:0.27863\n",
      "[105]\tvalidation_0-mlogloss:0.27697\n",
      "[106]\tvalidation_0-mlogloss:0.27565\n",
      "[107]\tvalidation_0-mlogloss:0.27383\n",
      "[108]\tvalidation_0-mlogloss:0.27187\n",
      "[109]\tvalidation_0-mlogloss:0.27060\n",
      "[110]\tvalidation_0-mlogloss:0.26945\n",
      "[111]\tvalidation_0-mlogloss:0.26831\n",
      "[112]\tvalidation_0-mlogloss:0.26637\n",
      "[113]\tvalidation_0-mlogloss:0.26550\n",
      "[114]\tvalidation_0-mlogloss:0.26360\n",
      "[115]\tvalidation_0-mlogloss:0.26182\n",
      "[116]\tvalidation_0-mlogloss:0.25969\n",
      "[117]\tvalidation_0-mlogloss:0.25804\n",
      "[118]\tvalidation_0-mlogloss:0.25691\n",
      "[119]\tvalidation_0-mlogloss:0.25519\n",
      "[120]\tvalidation_0-mlogloss:0.25413\n",
      "[121]\tvalidation_0-mlogloss:0.25293\n",
      "[122]\tvalidation_0-mlogloss:0.25119\n",
      "[123]\tvalidation_0-mlogloss:0.25003\n",
      "[124]\tvalidation_0-mlogloss:0.24893\n",
      "[125]\tvalidation_0-mlogloss:0.24782\n",
      "[126]\tvalidation_0-mlogloss:0.24689\n",
      "[127]\tvalidation_0-mlogloss:0.24540\n",
      "[128]\tvalidation_0-mlogloss:0.24415\n",
      "[129]\tvalidation_0-mlogloss:0.24289\n",
      "[130]\tvalidation_0-mlogloss:0.24105\n",
      "[131]\tvalidation_0-mlogloss:0.24012\n",
      "[132]\tvalidation_0-mlogloss:0.23911\n",
      "[133]\tvalidation_0-mlogloss:0.23776\n",
      "[134]\tvalidation_0-mlogloss:0.23671\n",
      "[135]\tvalidation_0-mlogloss:0.23542\n",
      "[136]\tvalidation_0-mlogloss:0.23396\n",
      "[137]\tvalidation_0-mlogloss:0.23295\n",
      "[138]\tvalidation_0-mlogloss:0.23162\n",
      "[139]\tvalidation_0-mlogloss:0.23017\n",
      "[140]\tvalidation_0-mlogloss:0.22844\n",
      "[141]\tvalidation_0-mlogloss:0.22696\n",
      "[142]\tvalidation_0-mlogloss:0.22587\n",
      "[143]\tvalidation_0-mlogloss:0.22469\n",
      "[144]\tvalidation_0-mlogloss:0.22391\n",
      "[145]\tvalidation_0-mlogloss:0.22313\n",
      "[146]\tvalidation_0-mlogloss:0.22178\n",
      "[147]\tvalidation_0-mlogloss:0.22091\n",
      "[148]\tvalidation_0-mlogloss:0.22010\n",
      "[149]\tvalidation_0-mlogloss:0.21845\n",
      "[150]\tvalidation_0-mlogloss:0.21740\n",
      "[151]\tvalidation_0-mlogloss:0.21608\n",
      "[152]\tvalidation_0-mlogloss:0.21487\n",
      "[153]\tvalidation_0-mlogloss:0.21407\n",
      "[154]\tvalidation_0-mlogloss:0.21311\n",
      "[155]\tvalidation_0-mlogloss:0.21155\n",
      "[156]\tvalidation_0-mlogloss:0.21083\n",
      "[157]\tvalidation_0-mlogloss:0.20986\n",
      "[158]\tvalidation_0-mlogloss:0.20884\n",
      "[159]\tvalidation_0-mlogloss:0.20811\n",
      "[160]\tvalidation_0-mlogloss:0.20728\n",
      "[161]\tvalidation_0-mlogloss:0.20603\n",
      "[162]\tvalidation_0-mlogloss:0.20471\n",
      "[163]\tvalidation_0-mlogloss:0.20365\n",
      "[164]\tvalidation_0-mlogloss:0.20274\n",
      "[165]\tvalidation_0-mlogloss:0.20172\n",
      "[166]\tvalidation_0-mlogloss:0.20069\n",
      "[167]\tvalidation_0-mlogloss:0.20004\n",
      "[168]\tvalidation_0-mlogloss:0.19930\n",
      "[169]\tvalidation_0-mlogloss:0.19857\n",
      "[170]\tvalidation_0-mlogloss:0.19752\n",
      "[171]\tvalidation_0-mlogloss:0.19643\n",
      "[172]\tvalidation_0-mlogloss:0.19566\n",
      "[173]\tvalidation_0-mlogloss:0.19500\n",
      "[174]\tvalidation_0-mlogloss:0.19399\n",
      "[175]\tvalidation_0-mlogloss:0.19321\n",
      "[176]\tvalidation_0-mlogloss:0.19244\n",
      "[177]\tvalidation_0-mlogloss:0.19156\n",
      "[178]\tvalidation_0-mlogloss:0.19054\n",
      "[179]\tvalidation_0-mlogloss:0.18973\n",
      "[180]\tvalidation_0-mlogloss:0.18878\n",
      "[181]\tvalidation_0-mlogloss:0.18792\n",
      "[182]\tvalidation_0-mlogloss:0.18682\n",
      "[183]\tvalidation_0-mlogloss:0.18619\n",
      "[184]\tvalidation_0-mlogloss:0.18535\n",
      "[185]\tvalidation_0-mlogloss:0.18442\n",
      "[186]\tvalidation_0-mlogloss:0.18370\n",
      "[187]\tvalidation_0-mlogloss:0.18281\n",
      "Training a XGBClassifier using a training set size of 6204. . .\n",
      "Trained model in 2.6640 seconds\n",
      "Made predictions in 0.0668 seconds.\n",
      "0.9584139264990329 0.9584139264990329\n",
      "F1 score and accuracy score for training set: 0.9584 , 0.9584.\n",
      "Made predictions in 0.0568 seconds.\n",
      "F1 score and accuracy score for test set: 0.9545 , 0.9545.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Define the parameter distribution to search\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.1),\n",
    "    'max_depth': randint(1, 5),\n",
    "    'subsample': uniform(0.8, 0.2),\n",
    "    'colsample_bytree': uniform(0.3, 0.5),\n",
    "    'n_estimators': randint(100, 200),\n",
    "}\n",
    "\n",
    "# Initialize xgb model with regularization parameters\n",
    "clf_xgb = XGBClassifier(seed=82, reg_alpha=0.1, reg_lambda=0.1, objective='multi:softmax', num_class=3, \n",
    "                        eval_metric='mlogloss')\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=clf_xgb, param_distributions=param_dist, n_iter=10, scoring='f1_micro', random_state=42, cv=5\n",
    ")\n",
    "\n",
    "# Perform random search on the resampled training set\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding score\n",
    "print(\"Best Parameters: \", random_search.best_params_)\n",
    "print(\"Best Score: {:.4f}\".format(random_search.best_score_))\n",
    "\n",
    "# Use the best model directly for early stopping\n",
    "best_model_xgb = random_search.best_estimator_\n",
    "\n",
    "# Set up evaluation sets for early stopping\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "evals = [(X_val, y_val)]\n",
    "\n",
    "# Train the XGBoost model with early stopping\n",
    "best_model_xgb.fit(X_train, y_train, eval_set=evals, early_stopping_rounds=20)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "train_predict(best_model_xgb, X_train, y_train, X_test, y_test) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
